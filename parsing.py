# Reference: https://blog.usejournal.com/writing-your-own-programming-language-and-compiler-with-python-a468970ae6dffrom rply import LexerGenerator, ParserGeneratorfrom productions import OP_TYPES, PRODUCTIONS, hex_intimport assembly# from operators import OPERATORS, LEVELS, OpType, ArgTypeACTIONS = [    "CPDOWNSP",    "RSADDI", "RSADDF", "RSADDS", "RSADDO",    "RSADDE0", "RSADDE1", "RSADDE2", "RSADDE3", "RSADDE4", "RSADDE5",    "RSADDLOC",    "CPTOPSP",    "CONSTI", "CONSTF", "CONSTS", "CONSTO",    "ACTION",    "LOGANDII", "LOGORII",    "BOOLANDII",    "EQII", "EQFF", "EQSS", "EQOO",    "EQTT",    "NEQII", "NEQFF", "NEQSS", "NEQOO",    "NEQTT",    "GEQII", "GEQFF",    "GTII", "GTFF",    "LTII", "LTFF",    "LEQII", "LEQFF",    "SHLEFTII", "SHRIGHTII", "USHRIGHTII",    "ADDII", "ADDIF", "ADDFI", "ADDFF", "ADDSS", "ADDVV",    "SUBII", "SUBIF", "SUBFI", "SUBFF", "SUBVV",    "MULII", "MULIF", "MULFI", "MULFF", "MULVF", "MULFV",    "DIVII", "DIVIF", "DIVFI", "DIVFF", "DIVVF",    "MODII",    "NEGI", "NEGF",    "COMPI",    "NOTI",    "MOVSP",    "JMP", "JSR", "JZ", "JNZ",    "RETN",    "DESTRUCT",    "DECSPI", "INCSPI",    "DECBPI", "INCBPI",    "CPDOWNBP", "CPTOPBP",    "SAVEBP", "RESTOREBP",    "STORESTATERETURN", "STORESTATE", "SSACTION", "SSJSR",    "NOOP",    "INLINERETN",    # "T"]# def line_map(x):#     nums = [line.split(" ")[0] for line in x.split("\n") if line.strip() != ""]#     return {int(nums[i], 16): i for i in range(len(nums))}class Lexer:    rules_before = [        # ("L_PAR", r"\("),        # ("R_PAR", r"\)"),        ("SEMI", r";"),    ]    rules_after = [        ("STRING", "\".*?\""),        ("VALUE", "-?[a-zA-Z0-9_\.]+")    ]    # We may or may not want to know about new lines    # Reference: https://stackoverflow.com/questions/3469080/match-whitespace-but-not-newlines    ignore = [        # ';.*?\n',        "\s+",        ","    ]    def __init__(self):        lexer_generator = LexerGenerator()        self.add_tokens(lexer_generator)        self.lexer = lexer_generator.build()    def get_all_rules(self):        rules = []        for rule in self.rules_before:            rules.append(rule)        for action in ACTIONS:            rules.append((action.upper(), action.upper()))        for rule in self.rules_after:            rules.append(rule)        return rules    def add_tokens(self, lexer):        # Add regex for all operators        # for t in types:        #     lexer.add(t.upper(), t)        for name, regex in self.get_all_rules():            lexer.add(name, regex)        # Add all ignore regex        for ignore_regex in self.ignore:            lexer.ignore(ignore_regex)    def lex(self, *args, **kwargs):        return self.lexer.lex(*args, **kwargs)def list_fn(p):    if len(p) == 1:        return [p[0]]    return [p[0]] + p[1]class Parser():    def __init__(self, lexer):        self.pg = ParserGenerator(            # A list of all token names accepted by the core.            list([x[0] for x in lexer.get_all_rules()]),            precedence=[                ("left", ["subroutine"]),                ("left", ["empty"])            ]        )        # @self.pg.production('program : rsadd_command jump_to_subroutine return subroutines')        # @self.pg.production('program : jump_to_subroutine return subroutines')        # def program(p):        #     # print("Program")        #     if len(p) == 4:        #         return assembly.Program(        #             None,        #             *p        #         )        #     return assembly.Program(        #         None,        #         None,        #         p[0],        #         p[1],        #         p[2]        #     )        # @self.pg.production('subroutines : subroutine subroutines')        # @self.pg.production('subroutines : subroutine')        # def subroutines(p):        #     return list_fn(p)        @self.pg.production("subroutine : commands return")        @self.pg.production("subroutine : return")        def subroutine(p):            # print(subroutine)            if len(p) == 2:                return assembly.Subroutine(p[0])            return assembly.Subroutine([])        @self.pg.production("return : RETN SEMI")        def ret(p):            r = assembly.Return()            # r.line_num = hex_int(p[0].getstr())            return r        @self.pg.production("commands : command commands")        @self.pg.production("commands : command")        def command_block(p):            # print("COmmands")            return list_fn(p)        for op_type in OP_TYPES:            self.create_op_type(op_type)        for prod_name in PRODUCTIONS:            self.create_command(prod_name)    def get_parser(self):        return self.pg.build()    def create_op_type(self, op_type):        def op_fn(p):            # print(op_type)            return p[0]        self.pg.production("command : " + op_type)(op_fn)    def create_command(self, prod_name):        def cmd_fn(p):            # print(prod_name)            return PRODUCTIONS[prod_name](p)        self.pg.production(prod_name)(cmd_fn)